% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/fit_poisson_nmf.R
\name{fit_poisson_nmf}
\alias{fit_poisson_nmf}
\alias{init_poisson_nmf}
\alias{fit_poisson_nmf_control_default}
\title{Fit or Re-fit Poisson Non-negative Matrix Factorization}
\usage{
fit_poisson_nmf(
  X,
  k,
  fit0,
  numiter = 100,
  method = c("em", "altsqp", "scd", "ccd", "mu"),
  control = list(),
  verbose = TRUE
)

init_poisson_nmf(
  X,
  F,
  L,
  k,
  beta = 0.5,
  betamax = 0.99,
  e = fit_poisson_nmf_control_default()$eps
)

fit_poisson_nmf_control_default()
}
\arguments{
\item{X}{The n x m matrix of counts; all entries of X should be
non-negative. It can be a sparse matrix (class \code{"dgCMatrix"})
or dense matrix (class \code{"matrix"}), with some exceptions (see
"Details").}

\item{k}{An integer 2 or greater giving the matrix rank for a
random initialization of the factors and loadings. (They are
initialized uniformly at random.) This argument should only be
specified if the initial estimates (\code{fit} or \code{F, L})
aren't already provided.}

\item{fit0}{Describe input argument "fit" here.}

\item{numiter}{The number of multiplicative updates to run.}

\item{method}{When \code{method = "em"}, the EM updates will be
performed; when \code{method = "mu"}, the multiplicative updates
will be performed. The multiplicative updates are only implemented
for dense count matrices; if \code{method = "mu"} and \code{X} is a
sparse matrix, and error will be generated.}

\item{control}{Describe input argument "control" here.}

\item{verbose}{When \code{verbose = TRUE}, information about the
algorithm's progress is printed to the console at each iteration.}

\item{F}{An optional argument giving is the initial estimate of the
factors (also sometimes called the "basis vectors"). It should be
an m x k matrix, where m is the number of columns in the counts
matrix X, and k > 1 is the rank of the matrix factorization, or,
equivalently, the number of topics. All entries of F should be
non-negative. When not provided, input argument \code{k} should be
specified.}

\item{L}{An optional argument giving the initial estimate of the
loadings (also sometimes called the "activations"). It should an n
x k matrix, where n is the number of rows in the counts matrix X,
and k > 1 is the rank of the matrix factorization. All entries of L
should be non-negative. When not provided, input argument \code{k}
should be specified.}

\item{beta}{Initial setting of the extrapolation parameter. This is
\eqn{beta} in Algorithm 3 of Ang & Gillis (2019).}

\item{betamax}{Initial setting for the upper bound on the
extrapolation parameter. This is \eqn{\bar{\gamma}} in Algorithm 3
of Ang & Gillis (2019).}

\item{e}{A small, non-negative number added to the terms inside the
logarithms to avoid computing logarithms of zero. This prevents
numerical problems at the cost of introducing a very small
inaccuracy in the computation.}
}
\value{
Both \code{init_poisson_nmf} and \code{fit_poisson_nmf}
return an object capturing the optimization algorithm state (for
\code{init_poisson_nmf}, this is the initial state). It is a list
with the following elements:

\item{F}{A matrix containing the factor estimates.}

\item{L}{A matrix containing estimates of the loadings.}

\item{Fy}{A matrix containing the extrapolated factor estimates. If
  the extrapolation scheme is not used, \code{F} and \code{Fy} will
  be the same.}

\item{Ly}{A matrix containing the extrapolated estimates of the
  loadings. If extrapolation is not used, \code{L} and \code{Ly} will
  be the same.}

\item{Fbest}{A matrix containing the current best estimates of the
  factors. If extrapolation is not used, \code{F} and \code{Fbest}
  will be the same.}

\item{Lbest}{A matrix containing the current best estimates of the
  loadings. If extrapolation is not used, \code{L} and \code{Lbest}
  will be the same.}

\item{loss}{Value of objective ("loss") function computed at the
  extrapolated solution for the loadings (\code{Ly}) and the
  non-extrapolated solution for the factors (\code{F}). This is used
  internally to implement the extrapolated updates.}

\item{lossbest}{Value of the objective ("loss" function computed at
  the current best estimates of the factors and loadings
  (\code{Fbest} and \code{Lbest}. If extrapolation is not used,
  \code{loss} and \code{lossbest} will be the same.}

\item{progress}{A data frame containing more detailed information
  about the algorithm's progress. The data frame should have
  \code{numiter} rows. The columns of the data frame are: "iter", the
  iteration number; "loglik", the log-likelihood at the current
  factor and loading estimates; "dev", the deviance at the current
  factor and loading estimates; "delta.l", the largest change in the
  factors matrix; "delta.f", the largest change in the loadings
  matrix; and "timing", the elapsed time in seconds (based on
  \code{\link{system.time}}).}
}
\description{
This function decomposes the input matrix X = L*F' by
  nonnegative matrix factorization (NMF) based on the "divergence"
  criterion; equivalently, it optimizes the likelihood under a
  Poisson model of the count data, X. It runs a specified number of
  multiplicative updates (MU) or expectation maximization (EM)
  updates to fit the L and F matrices.

  Although the EM updates are mathematically equivalent to the
  multiplicative updates, and therefore they share the same
  convergence properties, the implementation of EM is quite
  different; in particular, the EM updates are more suitable for
  sparse counts matrices.
}
\details{
The multiplicative and EM updates are very simple and
  fast. However, they can also be very slow to converge to a
  stationary point of the objective, particularly when the data are
  sparse.

  This function is mainly for internal use, and should only
  be called directly if you really know what you are doing. In
  particular, only minimal argument checking is performed; if you are
  not careful, you will get poor results are errors that are
  difficult to interpret.

  The implementation of the multiplicative updates is adapted from
  the MATLAB code by Daichi Kitamura \url{http://d-kitamura.net}.

  The "safeguard" step preventing the factors and loadings from
  exactly reaching zero is motivated by Theorem 1 of Gillis & Glineur
  (2012).

  An additional re-scaling step is performed at each iteration to
  promote numerical stability.

  Since the multiplicative updates are implemented using standard
  matrix operations, the speed is heavily dependent on the
  BLAS/LAPACK numerical libraries used. In particular, using
  optimized implementations such as OpenBLAS or Intel MKL can result
  in much improved performance of the multiplcative updates.
}
\examples{
# Simulate a 80 x 100 data set.
library(Matrix)
set.seed(1)
X <- simulate_count_data(80,100,3)$X

# Run 20 EM updates to find a good initialization.
fit0 <- fit_poisson_nmf(X,k = 3,numiter = 20,verbose = FALSE)

# The fit_poisson_nmf interface implements 5 different algorithms 
# for optimizing a Poisson non-negative matrix factorization. Let's
# compare their runtime and abiliity to identify a good "fit".
fit.mu     <- fit_poisson_nmf(X,fit0 = fit0,numiter = 400,
                              method = "mu",verbose = FALSE)
fit.em     <- fit_poisson_nmf(X,fit0 = fit0,numiter = 400,
                              method = "em",verbose = FALSE)
fit.ccd    <- fit_poisson_nmf(X,fit0 = fit0,numiter = 300,
                              method = "ccd",verbose = FALSE)
fit.scd    <- fit_poisson_nmf(X,fit0 = fit0,numiter = 300,
                              method = "scd",verbose = FALSE)
fit.altsqp <- fit_poisson_nmf(X,fit0 = fit0,numiter = 200,
                              method = "altsqp",verbose = FALSE)

clrs <- c("royalblue","skyblue","firebrick","orange","darkmagenta")
plot_progress_poisson_nmf(list(mu     = fit.mu,
                               em     = fit.em,
                               ccd    = fit.ccd,
                               scd    = fit.scd,
                               altsqp = fit.altsqp),
                          color = clrs)

# All optimization algorithms other than the multiplicative updates
# can handle sparse matrices as well as dense ones.
Y <- as(X,"dgCMatrix")
fit.em.sp     <- fit_poisson_nmf(Y,fit0 = fit0,numiter = 400,
                                 method = "em",verbose = FALSE)
fit.ccd.sp    <- fit_poisson_nmf(Y,fit0 = fit0,numiter = 300,
                                 method = "ccd",verbose = FALSE)
fit.scd.sp    <- fit_poisson_nmf(Y,fit0 = fit0,numiter = 300,
                                 method = "scd",verbose = FALSE)
fit.altsqp.sp <- fit_poisson_nmf(Y,fit0 = fit0,numiter = 200,
                                 method = "altsqp",verbose = FALSE)

plot_progress_poisson_nmf(list(em        = fit.em,
                               ccd       = fit.ccd,
                               scd       = fit.scd,
                               altsqp    = fit.altsqp,
                               em.sp     = fit.em.sp,
                               ccd.sp    = fit.ccd.sp,
                               scd.sp    = fit.scd.sp,
                               altsqp.sp = fit.altsqp.sp),
                          color = rep(clrs[-1],times = 2),
                          shape = rep(c(20,18),each = 4))

# The "extrapolated" updates can sometimes produce much better fits.
fit.ccd.ex <-
  fit_poisson_nmf(X,fit0 = fit0,numiter = 300,method = "ccd",
                  control = list(extrapolate = TRUE),verbose = FALSE)
fit.scd.ex <-
  fit_poisson_nmf(X,fit0 = fit0,numiter = 300,method = "scd",
                  control = list(extrapolate = TRUE),verbose = FALSE)
fit.altsqp.ex <-
  fit_poisson_nmf(X,fit0 = fit0,numiter = 200,method = "altsqp",
                  control = list(extrapolate = TRUE),verbose = FALSE)

plot_progress_poisson_nmf(list(ccd       = fit.ccd,
                               scd       = fit.scd,
                               altsqp    = fit.altsqp,
                               ccd.ex    = fit.ccd.ex,
                               scd.ex    = fit.scd.ex,
                               altsqp.ex = fit.altsqp.ex),
                               color = rep(clrs[3:5],times = 2),
                               shape = rep(c(20,18),each = 3))

}
\references{
Gillis, N. and Glineur, F. (2012). Accelerated multiplicative
  updates and hierarchical ALS algorithms for nonnegative matrix
  factorization. \emph{Neural Computation} \code{24}, 1085–1105. 

  Lee, D. D. and Seung, H. S. (2001). Algorithms for
  non-negative matrix factorization. In \emph{Advances in Neural
  Information Processing Systems} \bold{13}, 556–562.
}
