% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/fit_poisson_nmf.R
\name{fit_poisson_nmf}
\alias{fit_poisson_nmf}
\alias{init_poisson_nmf}
\alias{fit_poisson_nmf_control_default}
\title{Fit or Re-fit Poisson Non-negative Matrix Factorization}
\usage{
fit_poisson_nmf(
  X,
  k,
  fit0,
  numiter = 100,
  method = c("em", "scd", "ccd", "altsqp", "mu"),
  control = list(),
  verbose = TRUE
)

init_poisson_nmf(
  X,
  F,
  L,
  k,
  beta = 0.5,
  betamax = 0.99,
  minval = fit_poisson_nmf_control_default()$minval,
  e = fit_poisson_nmf_control_default()$eps
)

fit_poisson_nmf_control_default()
}
\arguments{
\item{X}{The n x m matrix of counts; all entries of X should be
non-negative. It can be a sparse matrix (class \code{"dgCMatrix"})
or dense matrix (class \code{"matrix"}), with some exceptions (see
\sQuote{Details}).}

\item{k}{An integer 2 or greater giving the matrix rank for a
random initialization of the factors and loadings. (They are
initialized uniformly at random.) This argument should only be
specified if the initial fit (\code{fit0} or \code{F, L}) are not
already provided.}

\item{fit0}{The initial model fit. It should be an object of class
\dQuote{poisson_nmf_fit}, such as an output from
\code{init_poisson_nmf}, or from a previous call to
\code{fit_poisson_nmf}.}

\item{numiter}{The number of updates of the factors and loadings to
perform.}

\item{method}{The method to use for updating the factors and
loadings. Five methods are implemented: multiplicative updates,
\code{method = "mu"}; expectation maximization (EM), \code{method =
"em"}; sequential co-ordinate descent (SCD), \code{method = "scd"};
cyclic co-ordinate descent (CCD), \code{method = "ccd"}; and the
alternating sequential quadratic programming (alt-SQP) method,
\code{method = "altsqp"}. See \sQuote{Details} for a detailed
description of these methods.}

\item{control}{A list of parameters controlling the behaviour of
the optimization algorithm. See \sQuote{Details}.}

\item{verbose}{When \code{verbose = TRUE}, information about the
algorithm's progress is printed to the console at each iteration.}

\item{F}{An optional argument giving is the initial estimate of the
factors (also sometimes called the "basis vectors"). It should be
an m x k matrix, where m is the number of columns in the counts
matrix \code{X}, and k > 1 is the rank of the matrix factorization
(equivalently, the number of "topics"). All entries of \code{F}
should be non-negative. When not provided, input argument \code{k}
should be specified instead.}

\item{L}{An optional argument giving the initial estimate of the
loadings (also sometimes called the "activations"). It should an n
x k matrix, where n is the number of rows in the counts matrix
\code{X}, and k > 1 is the rank of the matrix factorization
(equivalently, the number of "topics"). All entries of \code{L}
should be non-negative. When not provided, input argument \code{k}
should be specified instead.}

\item{beta}{Initial setting of the extrapolation parameter. This is
\eqn{beta} in Algorithm 3 of Ang & Gillis (2019).}

\item{betamax}{Initial setting for the upper bound on the
extrapolation parameter. This is \eqn{\bar{\gamma}} in Algorithm 3
of Ang & Gillis (2019).}

\item{minval}{A small, positive constant used to safeguard the}

\item{e}{A small, non-negative number added to the terms inside the
logarithms to avoid computing logarithms of zero. See the
description of \code{control$eps} in "Details" for more
information.}
}
\value{
Both \code{init_poisson_nmf} and \code{fit_poisson_nmf}
return an object capturing the optimization algorithm state (for
\code{init_poisson_nmf}, this is the initial state). It is a list
with the following elements:

\item{F}{A matrix containing the current best estimates of the
  factors.}

\item{L}{A matrix containing the current best estimates of the
  loadings.}

\item{Fn}{A matrix containing the non-extrapolated factor estimates.
  If extrapolation is not used, \code{Fn} and \code{F} will be the
  same.}

\item{Ln}{A matrix containing the non-extrapolated estimates of the
  loadings. If extrapolation is not used, \code{Ln} and \code{L} will
  be the same.}

\item{Fy}{A matrix containing the extrapolated factor estimates. If
  the extrapolation scheme is not used, \code{Fy} and \code{F} will
  be the same.}

\item{Ly}{A matrix containing the extrapolated estimates of the
  loadings. If extrapolation is not used, \code{Ly} and \code{L} will
  be the same.}

\item{loss}{Value of the objective (\dQuote{loss}) function
  computed at the current best estimates of the factors and
  loadings.}

\item{loss.fnly}{Value of the objective (\dQuote{loss}) function
  computed at the extrapolated solution for the loadings (\code{Ly})
  and the non-extrapolated solution for the factors (\code{Fn}). This
  is used internally to implement the extrapolated updates.}

\item{beta}{The extrapolation parameter, \eqn{beta} in Algorithm 3
  of Ang & Gillis (2019).}

\item{betamax}{Upper bound on the extrapolation parameter. This is
  \eqn{\bar{\gamma}} in Algorithm 3 of Ang & Gillis (2019).}

\item{beta0}{The setting of the extrapolation parameter at the
  last iteration that improved the solution.}

\item{progress}{A data frame containing detailed information about
  the algorithm's progress. The data frame should have \code{numiter}
  rows. The columns of the data frame are: "iter", the iteration
  number; "loglik", the log-likelihood at the current best factor and
  loading estimates; "dev", the deviance at the current best factor
  and loading estimates; "res", the maximum residual of the
  Karush-Kuhn-Tucker (KKT) first-order optimality conditions at the
  current best factor and loading estimates; "delta.f", the largest
  change in the factors matrix; "delta.l", the largest change in the
  loadings matrix; "nonzeros.f", the proportion of entries in the
  factors matrix that are nonzero; "nonzeros.l", the proportion of
  entries in the loadings matrix that are nonzero; "extrapolate",
  which is 1 if extrapolation is used, otherwise it is 0; "beta", the
  setting of the extrapolation parameter; "betamax", the setting of
  the extrapolation parameter upper bound; and "timing", the elapsed
  time in seconds (recorded using \code{\link{proc.time}}).}
}
\description{
This function decomposes the input matrix X = L*F' by
  nonnegative matrix factorization (NMF) based on the
  \dQuote{divergence} criterion; equivalently, it optimizes the
  likelihood under a Poisson model of the count data, X. It runs a
  specified number of multiplicative updates (MU) or expectation
  maximization (EM) updates to fit the L and F matrices.

  Although the EM updates are mathematically equivalent to the
  multiplicative updates, and therefore they share the same
  convergence properties, the implementation of EM is quite
  different; in particular, the EM updates are more suitable for
  sparse counts matrices.
}
\details{
The multiplicative and EM updates are very simple and
  fast. However, they can also be very slow to converge to a
  stationary point of the objective, particularly when the data are
  sparse.

  Using this function requires some care; only minimal argument
  checking is performed, and error messages may not be helpful.

  The implementation of the multiplicative updates is adapted from
  the MATLAB code by Daichi Kitamura \url{http://d-kitamura.net}.

  The "safeguard" step preventing the factors and loadings from
  exactly reaching zero is motivated by Theorem 1 of Gillis & Glineur
  (2012).

  An additional re-scaling step is performed at each iteration to
  promote numerical stability.

  Since the multiplicative updates are implemented using standard
  matrix operations, the speed is heavily dependent on the
  BLAS/LAPACK numerical libraries used. In particular, using
  optimized implementations such as OpenBLAS or Intel MKL can result
  in much improved performance of the multiplcative updates.
}
\examples{
# Simulate a 80 x 100 data set.
library(Matrix)
set.seed(1)
X <- simulate_count_data(80,100,3)$X

# Run 20 EM updates to find a good initialization.
fit0 <- fit_poisson_nmf(X,k = 3,numiter = 20,verbose = FALSE)

# The fit_poisson_nmf interface implements 5 different algorithms 
# for optimizing a Poisson non-negative matrix factorization. Let's
# run the different algoriths, and compare the quality of the fits.
fit.mu     <- fit_poisson_nmf(X,fit0 = fit0,numiter = 400,
                              method = "mu",verbose = FALSE)
fit.em     <- fit_poisson_nmf(X,fit0 = fit0,numiter = 400,
                              method = "em",verbose = FALSE)
fit.ccd    <- fit_poisson_nmf(X,fit0 = fit0,numiter = 300,
                              method = "ccd",verbose = FALSE)
fit.scd    <- fit_poisson_nmf(X,fit0 = fit0,numiter = 300,
                              method = "scd",verbose = FALSE)
fit.altsqp <- fit_poisson_nmf(X,fit0 = fit0,numiter = 200,
                              method = "altsqp",verbose = FALSE)

clrs <- c("royalblue","skyblue","firebrick","orange","darkmagenta")
fits <- list(mu = fit.mu,em = fit.em,ccd = fit.ccd,scd = fit.scd,
             altsqp = fit.altsqp)
print(compare_poisson_nmf_fits(fits),digits = 8)
plot_progress_poisson_nmf(fits,y = "loglik",colors = clrs)
plot_progress_poisson_nmf(fits,y = "res",colors = clrs)

# All algorithms except the multiplicative updates can handle
# sparse matrices as well as dense ones.
Y <- as(X,"dgCMatrix")
fit.em.sp     <- fit_poisson_nmf(Y,fit0 = fit0,numiter = 400,
                                 method = "em",verbose = FALSE)
fit.ccd.sp    <- fit_poisson_nmf(Y,fit0 = fit0,numiter = 300,
                                 method = "ccd",verbose = FALSE)
fit.scd.sp    <- fit_poisson_nmf(Y,fit0 = fit0,numiter = 300,
                                 method = "scd",verbose = FALSE)
fit.altsqp.sp <- fit_poisson_nmf(Y,fit0 = fit0,numiter = 200,
                                 method = "altsqp",verbose = FALSE)
fits <- list(em = fit.em,ccd = fit.ccd,scd = fit.scd,altsqp = fit.altsqp,
             em.sp = fit.em.sp,ccd.sp = fit.ccd.sp,scd.sp = fit.scd.sp,
             altsqp.sp = fit.altsqp.sp)
print(compare_poisson_nmf_fits(fits),digits = 8)
plot_progress_poisson_nmf(fits,colors = clrs[-1],
                          shapes = rep(c(19,21),each = 4))

# The "extrapolated" updates can sometimes produce much better fits.
fit.ccd.ex <-
  fit_poisson_nmf(X,fit0 = fit0,numiter = 300,method = "ccd",
                  control = list(extrapolate = TRUE),verbose = FALSE)
fit.scd.ex <-
  fit_poisson_nmf(X,fit0 = fit0,numiter = 300,method = "scd",
                  control = list(extrapolate = TRUE),verbose = FALSE)
fit.altsqp.ex <-
  fit_poisson_nmf(X,fit0 = fit0,numiter = 200,method = "altsqp",
                  control = list(extrapolate = TRUE),verbose = FALSE)
fits <- list(ccd = fit.ccd,scd = fit.scd,altsqp = fit.altsqp,
             ccd.ex = fit.ccd.ex,scd.ex = fit.scd.ex,
             altsqp.ex = fit.altsqp.ex)
print(compare_poisson_nmf_fits(fits),digits = 8)
plot_progress_poisson_nmf(fits,y = "loglik",
                          colors = clrs[3:5],
                          shapes = rep(c(19,21),each = 3))
plot_progress_poisson_nmf(fits,y = "res",
                          colors = clrs[3:5],
                          shapes = rep(c(19,21),each = 3))

}
\references{
Gillis, N. and Glineur, F. (2012). Accelerated multiplicative
  updates and hierarchical ALS algorithms for nonnegative matrix
  factorization. \emph{Neural Computation} \code{24}, 1085–1105. 

  Lee, D. D. and Seung, H. S. (2001). Algorithms for
  non-negative matrix factorization. In \emph{Advances in Neural
  Information Processing Systems} \bold{13}, 556–562.

  Lin, X. and Boutros, P. C. (2018). Fast nonnegative matrix
  factorization and applications to pattern extraction, deconvolution
  and imputation. \emph{bioRxiv} doi:10.1101/321802.
}
